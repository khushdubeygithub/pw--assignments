{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7bd38c8",
   "metadata": {},
   "source": [
    "# Basic of ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45acf09",
   "metadata": {},
   "source": [
    "AI (Artificial Intelligence):\n",
    "AI refers to the simulation of human intelligence processes by machines, especially computer systems. It involves tasks such as learning, reasoning, problem-solving, perception, and language understanding.\n",
    "\n",
    "ML (Machine Learning):\n",
    "ML is a subset of AI that focuses on the development of algorithms and statistical models that allow computers to learn from and make predictions or decisions based on data. It involves improving performance on a task by learning from data, without being explicitly programmed.\n",
    "\n",
    "DL (Deep Learning):\n",
    "DL is a subfield of ML that involves the use of artificial neural networks to model and solve complex problems. It is particularly effective for tasks such as image and speech recognition, and it has gained popularity due to its ability to automatically learn features from raw data.\n",
    "\n",
    "DS (Data Science):\n",
    "DS is the field of study that combines domain expertise, programming skills, and knowledge of mathematics and statistics to extract valuable insights and knowledge from data.\n",
    "\n",
    "Q2: What is supervised learning? List some examples of supervised learning.\n",
    "Supervised learning is a type of machine learning where the algorithm learns from labeled training data to make predictions or decisions. It involves mapping input data to the correct output label. Examples include image classification, spam email detection, and predicting house prices.\n",
    "\n",
    "Q3: What is unsupervised learning? List some examples of unsupervised learning.\n",
    "Unsupervised learning is a type of machine learning where the algorithm learns from unlabeled data to find hidden patterns or structure. Examples include clustering similar documents, customer segmentation, and topic modeling.\n",
    "\n",
    "Q4: What is the difference between AI, ML, DL, and DS?\n",
    "AI is the broader concept of simulating human intelligence using machines, ML is a subset of AI that focuses on learning from data, DL is a subset of ML that uses deep neural networks, and DS is the field that involves extracting insights from data.\n",
    "\n",
    "Q5: What are the main differences between supervised, unsupervised, and semi-supervised learning?\n",
    "In supervised learning, the model is trained on labeled data to make predictions. In unsupervised learning, the model finds patterns or structures in unlabeled data. Semi-supervised learning uses a combination of labeled and unlabeled data.\n",
    "\n",
    "Q6: What is train, test, and validation split? Explain the importance of each term.\n",
    "Train, test, and validation split is the process of dividing a dataset into three parts. The training set is used to train the model, the validation set is used to tune hyperparameters, and the test set is used to evaluate the model's final performance on unseen data.\n",
    "\n",
    "Q7: How can unsupervised learning be used in anomaly detection?\n",
    "Unsupervised learning can be used in anomaly detection by learning the normal patterns of the data and flagging instances that deviate significantly from those patterns as anomalies.\n",
    "\n",
    "Q8: List down some commonly used supervised learning algorithms and unsupervised learning algorithms.\n",
    "Commonly used supervised learning algorithms: Linear Regression, Decision Trees, Random Forest, Support Vector Machines, Neural Networks.\n",
    "Commonly used unsupervised learning algorithms: K-Means Clustering, Hierarchical Clustering, Principal Component Analysis (PCA), Gaussian Mixture Models (GMM).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55858b3",
   "metadata": {},
   "source": [
    "# Variance , Bais , underfitting , overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2d38e2",
   "metadata": {},
   "source": [
    "Q1: Overfitting occurs when a machine learning model learns the training data too well, capturing noise and random fluctuations that do not generalize to new, unseen data. This can lead to poor performance on new data. Underfitting, on the other hand, happens when a model is too simple to capture the underlying patterns in the data, resulting in poor performance on both the training and test data. Overfitting can be mitigated by using techniques such as regularization, reducing model complexity, and increasing training data. Underfitting can be addressed by using more complex models and improving feature engineering.\n",
    "\n",
    "Q2: To reduce overfitting, you can:\n",
    "- Use more training data.\n",
    "- Simplify the model architecture.\n",
    "- Apply regularization techniques (L1, L2 regularization).\n",
    "- Use cross-validation to evaluate model performance.\n",
    "- Remove irrelevant features or use feature selection.\n",
    "\n",
    "Q3: Underfitting occurs when a model is too simple to capture the underlying patterns in the data. Scenarios where underfitting can occur include using linear models for complex nonlinear relationships, using too few features, or using a low-complexity model when the data is inherently complex.\n",
    "\n",
    "Q4: The bias-variance tradeoff refers to the balance between the model's ability to capture the true underlying patterns (low bias) and its sensitivity to noise and fluctuations in the data (high variance). High bias implies the model is too simplistic, ignoring important patterns. High variance implies the model is too complex and capturing noise. Adjusting this tradeoff can help achieve better generalization.\n",
    "\n",
    "Q5: Common methods for detecting overfitting and underfitting include:\n",
    "- Plotting learning curves.\n",
    "- Cross-validation.\n",
    "- Analyzing training and validation/test error.\n",
    "- Regularization parameter tuning.\n",
    "- Visual inspection of predictions.\n",
    "\n",
    "Q6: Bias refers to the error due to overly simplistic assumptions in the learning algorithm. High bias models may oversimplify the problem. Variance refers to the error due to too much complexity in the learning algorithm, capturing noise. High variance models may fit the training data too closely. Examples of high bias models include linear regression on a complex nonlinear problem. High variance models include decision trees with too many branches.\n",
    "\n",
    "Q7: Regularization is a technique used to prevent overfitting by adding a penalty term to the loss function. Common regularization techniques include L1 regularization (Lasso), L2 regularization (Ridge), and Elastic Net (combining L1 and L2). Regularization works by discouraging large parameter values, which helps prevent the model from fitting noise in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc8e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
