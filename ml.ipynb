{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa3fac46",
   "metadata": {},
   "source": [
    "# Basic of ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58da6c97",
   "metadata": {},
   "source": [
    "Q1:\n",
    "C) Artificial Intelligence\n",
    "D) Machine Learning\n",
    "I) Deep Learning\n",
    "\n",
    "Q2: Supervised Learning involves training a model on labeled data, where the algorithm learns to map input to output based on provided examples. Examples: Image classification, spam email detection, predicting house prices.\n",
    "\n",
    "Q3: Unsupervised Learning involves training a model on unlabeled data, where the algorithm identifies patterns and relationships within the data. Examples: Clustering similar customer groups, topic modeling in text data.\n",
    "\n",
    "Q4: \n",
    "- AI (Artificial Intelligence) is a broad concept that aims to create machines capable of intelligent behavior.\n",
    "- ML (Machine Learning) is a subset of AI that focuses on enabling machines to learn from data and improve over time.\n",
    "- DL (Deep Learning) is a subset of ML that uses neural networks with multiple layers to model and solve complex problems.\n",
    "- DS (Data Science) involves extracting insights and knowledge from data, which can involve AI, ML, and DL techniques.\n",
    "\n",
    "Q5: \n",
    "- Supervised Learning uses labeled data for training and aims to predict the output.\n",
    "- Unsupervised Learning finds patterns in unlabeled data, such as clustering and dimensionality reduction.\n",
    "- Semi-Supervised Learning combines both labeled and unlabeled data for training.\n",
    "\n",
    "Q6: Train, test, and validation split is a common practice in ML. Training data is used to train the model, validation data helps tune hyperparameters, and the test data evaluates the final model's performance. Proper split helps prevent overfitting.\n",
    "\n",
    "Q7: Unsupervised Learning can be used in anomaly detection by identifying data points that deviate from the norm or expected patterns, helping detect unusual behavior or events.\n",
    "\n",
    "Q8: \n",
    "Common Supervised Learning Algorithms: Linear Regression, Decision Trees, Random Forest, Support Vector Machines, Neural Networks (for image recognition).\n",
    "Common Unsupervised Learning Algorithms: K-Means Clustering, Hierarchical Clustering, Principal Component Analysis (PCA), t-SNE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0424ef6",
   "metadata": {},
   "source": [
    "# Variance , Bais , underfitting , overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48b3668",
   "metadata": {},
   "source": [
    "Q1: Overfitting occurs when a machine learning model learns the training data too well, capturing noise and random fluctuations that do not generalize to new, unseen data. This can lead to poor performance on new data. Underfitting, on the other hand, happens when a model is too simple to capture the underlying patterns in the data, resulting in poor performance on both the training and test data. Overfitting can be mitigated by using techniques such as regularization, reducing model complexity, and increasing training data. Underfitting can be addressed by using more complex models and improving feature engineering.\n",
    "\n",
    "Q2: To reduce overfitting, you can:\n",
    "- Use more training data.\n",
    "- Simplify the model architecture.\n",
    "- Apply regularization techniques (L1, L2 regularization).\n",
    "- Use cross-validation to evaluate model performance.\n",
    "- Remove irrelevant features or use feature selection.\n",
    "\n",
    "Q3: Underfitting occurs when a model is too simple to capture the underlying patterns in the data. Scenarios where underfitting can occur include using linear models for complex nonlinear relationships, using too few features, or using a low-complexity model when the data is inherently complex.\n",
    "\n",
    "Q4: The bias-variance tradeoff refers to the balance between the model's ability to capture the true underlying patterns (low bias) and its sensitivity to noise and fluctuations in the data (high variance). High bias implies the model is too simplistic, ignoring important patterns. High variance implies the model is too complex and capturing noise. Adjusting this tradeoff can help achieve better generalization.\n",
    "\n",
    "Q5: Common methods for detecting overfitting and underfitting include:\n",
    "- Plotting learning curves.\n",
    "- Cross-validation.\n",
    "- Analyzing training and validation/test error.\n",
    "- Regularization parameter tuning.\n",
    "- Visual inspection of predictions.\n",
    "\n",
    "Q6: Bias refers to the error due to overly simplistic assumptions in the learning algorithm. High bias models may oversimplify the problem. Variance refers to the error due to too much complexity in the learning algorithm, capturing noise. High variance models may fit the training data too closely. Examples of high bias models include linear regression on a complex nonlinear problem. High variance models include decision trees with too many branches.\n",
    "\n",
    "Q7: Regularization is a technique used to prevent overfitting by adding a penalty term to the loss function. Common regularization techniques include L1 regularization (Lasso), L2 regularization (Ridge), and Elastic Net (combining L1 and L2). Regularization works by discouraging large parameter values, which helps prevent the model from fitting noise in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb60fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
